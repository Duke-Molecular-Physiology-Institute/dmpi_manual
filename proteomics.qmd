# Proteomics

## Introduction {#sec-intro}

This section template is designed to give a step-by-step walk-through of the data analysis performed in @lyons_proteomics_2022, which served as a companion manuscript to @wilson_disruption_2022. The goal of the analysis was to determine the effects of STIM1 knockout (KO) on protein abundance and sites of protein phosphorylation in gastrocnemius muscle tissue using data from large-scale proteomics and phosphoproteomics experiments. The data considered here consist of protein abundance values obtained from five STIM<sup>fl/fl</sup> mice and five STIM<sup>-/-</sup> mice. The code used in this section is based on the R code accompanying the @lyons_proteomics_2022 article.

Part of the goal of this section is to identify common steps in analyzing 'omics datasets, to organize them in an understandable way, and to provide examples of how to perform the analysis steps using R.

## Before analysis {#sec-before}

Depending on the nature of your experiment, you may be ready to analyze your data as soon as it comes off the machine, or there may be several steps of cleaning and pre-processing before it makes sense to draw conclusions from your data. This tutorial organizes the most common steps before data analysis into three categories: 1. loading the data, 2. filtering the data, and 3. normalizing the data.

### Loading the data into R

Before working with data in R, it needs to be loaded from the raw files that come off the machine (or other files that you have created) into R objects. In this tutorial we will be working with plain text files, which can be read with the R package `readr`. The package `readr` is part of a host of packages included in `tidyverse`, so we will load that, along with other packages, which will help us write concise code. Online documentation for all of these packages can be found in @sec-rdocs.

```{r, message=F, warning=F}
library(tidyverse)
library(janitor)
library(magrittr)
```

Since the files we are working with here have a `.txt` extension and are tab-separated, we can use the `read_tsv` command in the `readr` package to load them into R:

```{r, message=F, warning=F}
# load mito_carta file for mitochondria data
mito_carta = readr::read_tsv("data/Mouse.MitoCarta3.0.txt")
colnames(mito_carta)[[1]] = "GeneName"
  
# load the peptide and protein data
peptides = readr::read_tsv("data/Muoio_BeckyWilson_STIM1-SKM_TMT10_FINAL_2020-05-03_SN2pt5_PeptideIsoforms.txt")
proteins = readr::read_tsv("data/Muoio_BeckyWilson_STIM1-SKM_TMT10_FINAL_2020-05-03_SN2pt5_Proteins.txt")

# create variables for the samples being compared and the total number of samples
ID_names = c("WT", "KO", "pool")
total_number_of_samples = 11
```

Note that the `readr::read_tsv` syntax above is overkill; once we load the `tidyverse` library, we can use functions within an R package without specifying the package name. However, in a tutorial like this, writing out the package name can help with understanding where each function comes from. Doing so also provides a visual cue that we are using a function from an R package.

Once you have loaded your data into an R object, it is always a good idea to visually inspect the R object to determine whether the data have been loaded correctly. You can preview tabular R objects, like the `proteins` object above, using the `View()` command as follows:

```{r, eval=F}
View(proteins)
```

### Filtering the data

Filtering data is the process of discarding pieces of a dataset that will not be used in subsequent normalization or analysis steps. It is a conceptually trivial step that can, in practice, take a fair amount of care, consideration, and time. The basic principle is that if some part of your primary dataset will not be used in subsequent steps, it is a good idea to trim this part from the R objects you are using to store your data.

In our example, we will first filter our data by extracting the columns we need. We'll store these names in an R object:

```{r}
columns_to_extract = list(cols_protein = janitor::make_clean_names(c("Description", "Accession", "Master", "Exp. q-value: Combined",
                                     "# Peptides", "# PSMs", "# Protein Unique Peptides", "# Unique Peptides", "Entrez Gene ID",
                                      "Reactome Pathways", "WikiPathways")),
                          cols_peptide = janitor::make_clean_names(c("Master Protein Accessions", "Protein Accessions", "Sequence",
                                             "# Missed Cleavages", "PSM Ambiguity", "# PSMs", 
                                             "Modifications", "Modifications in Proteins", "XCorr (by Search Engine): Sequest HT",
                                             "Deltam/z [Da] (by Search Engine): Sequest HT"
                                             )))
```

Then we will filter the protein and peptide R objects so that we remove the columns we don't need:

```{r}
filtered_proteins = proteins %>%
                    janitor::clean_names() %>%
                    dplyr::select(., dplyr::all_of(columns_to_extract[["cols_protein"]]), dplyr::starts_with("abundance_F2_"))

filtered_peptides = peptides %>%
                    janitor::clean_names() %>%
                    dplyr::select(., dplyr::all_of(columns_to_extract[["cols_peptide"]]), dplyr::starts_with("abundance_F6_"))
```


### Normalizing the data

Some form of normalization is frequently required before drawing conclusions from 'omics datasets. There are two primary reasons for this: 

1. **Batch effects:** The data that were recorded may have been subject to a systematic artifact that can be detected and potentially adjusted for.
2. **Measurement scaling**: The raw values that are measured by the 'omics technology do not correspond directly to the underlying value that we are interested in. For instance, measurement devices may measure absolute abundance of a biological product such as a protein, transcript, or metabolite, whereas we may be interested in the *relative* abundance of that product. The absolute value may be a function of the experimental protocol, rather than a function of the relevant biology.

## Exploratory Data Analysis {#sec-eda}

## Statistical testing {#sec-stattest}

In this tutorial, we are interested in testing the difference in protein abundance between WT and STIM1 KO mice. The two types of mice represent two distinct populations, and the specific mice used in our experiment are a small sample from these populations. For a given protein---let's call it protein $j$---we would like to know whether the population average abundance among WT mice is the same or different than the population average abundance among STIM1 KO mice. We can resolve this question by testing the null hypothesis that says the average abundances are the same:
$$
H_0: m^{\text{WT}}_j = m^{\text{KO}}_j,
$$
versus the alternative hypothesis, which says they are different:
$$
H_1: m^{\text{WT}}_j \neq m^{\text{KO}}_j.
$$

We will use a version of the two-sample $t$-test to decide this question for each protein.

## Statistical language {#sec-statlang}

